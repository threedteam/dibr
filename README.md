# README



This repository contains code for three different models, each corresponding to a specific algorithm:



## 1、**Depth-aware Decomposition**

This folder contains code related to the Depth-aware Decomposition algorithm.



**Overview**

1. **Input Preparation**: Users need to prepare RGB image files and depth map files as input.
2. **Running the Code**: When executing the code, the system will automatically read the input files and apply the algorithm for processing.
3. **Parameter Adjustment**: In the `object_decomposition` section, users can control the final mask result by adjusting hyperparameters. 
4. **Output Generation**: Once the processing is complete, the code will generate the foreground objects mask and save it as an image file.

**Main codes:**

	fg_inference_w_depth.py ： Uses depth information for foreground objects extraction. It takes the paths of color images and depth images as input and outputs the extracted foreground object mask.
	
	|    |
	|    ——object_decomposition: Selects foreground objects by utilizing the depth map, object mask, and a threshold as input. The final result can be controlled through the hyperparameters TD (threshold) and TF (percent). 
	|    |
	|    ——run_on_image: Performs instance segmentation.

**Key hyperparameter settings**

| TD (threshold) | TF (percent) | task     |
| -------------- | ------------ | -------- |
| 3              | 0.5          | instance |

**Example：**

```
python demo.py 
  --config-file ../configs/ade20k/swin/oneformer_swin_large_bs16_160k.yaml \
  --input <path-to-RGB images> \
  --depth <path-to-depth maps> \
  --output <output-path> \
  --task $task \
  --opts MODEL.IS_TRAIN False MODEL.IS_DEMO True
    MODEL.WEIGHTS <path-to-checkpoint>
```



## 2、**Masked 3D Image Warping**

This folder contains code related to the Masked 3D Image Warping algorithm.

**Overview**

1. **Input Preparation**: Prepare input files including reference view files, depth map files, and the foreground object mask generated by the depth-aware decomposition model.

2. **Running the Code**: Execute the `main.m` script to run the code. Ensure that the input and output paths are correctly set within the script.

3. **Parameter Adjustment**: Adjust parameters in the `threed_image_warping_wmask` and `big_hole_dilation` sections using the default values provided in the table.

4. **Output Generation**: The generated outputs include target views with and without foreground objects along with their associated masks, as well as the warped foreground object mask.

   

**Main codes:**

```
main.m: Masked 3D Image Warping Algorithm Source Code File

	|    ——threed_image_warping_wmask:3D image warping. It generates the target view from a reference view along with its corresponding depth map and foreground object mask for any viewpoint.
	|    |
	|    ——detect_holes.m: Hole detection. It detects holes in the target view.
	|    |
	|    ——big_hole_dilation.m: Dilating large holes. It dilates large holes based on the depth map.
	|    |
	|     T_D_calculate.m: Calculates the threshold for identifying foreground objects.
```

**Key hyperparameter settings**

The default hyperparameters were used in `big_hole_dilation.m` and `threed_image_warping_wmask`.

| th_big_hole = 3 | sharp_th | n_dilation | th_d | th_e |
| --------------- | -------- | ---------- | ---- | ---- |
| 3               | 4        | 3          | 8    | 10   |





## 3、 Background Reconstruction algorithm.

This folder contains code related to the Background Reconstruction algorithm.

**Overview**

1. **Input Preparation**: Before running the code, ensure to prepare input target views with holes and their associated masks for inference. Use `find_bk.py` to prepare training datasets.
2. **Running the Code**: Execute the provided main codes to accomplish tasks such as generating hole-filled target views, training the generator, implementing a layered merging algorithm, creating masked datasets, calculating metrics, and preparing background image datasets.
3. **Parameter Adjustment**:Fine-tune hyperparameters and configurations in the respective code files and configuration document as needed for optimal performance.
4. **Output Generation**: Utilize `predict.py` to generate final hole-filled target views, train the generator, and implement layered merging algorithms using `copy_final.py`.

**Main codes:**

```
	|    ——predict.py: Generates the final hole-filled target view from the input target view with holes and its associated mask.
	|    |
	|    ——train.py: Used for training the generator with a batch size of 60. Additional training configurations can be found and set in the configuration document.
	|    |
	|    ——copy_final.py: Implements a layered merging algorithm to combine the predicted foreground and background layers.
	|    |
	|     gen_mask_dataset.py: Generates a masked dataset for training and evaluation purposes.
	|    |
	|    ——metrics.py: Contains metrics calculations.
	|    |
	|     find_bk.py: Prepares a dataset consisting of pure background images.
	
```

**Key hyperparameter settings**

| Learning Rate(Generator) | Learning Rate(Discriminator) | Epoch | train_batch_size | val_batch_size |
| ------------------------ | ---------------------------- | ----- | ---------------- | -------------- |
| 0.001                    | 0.0001                       | 60    | 6                | 2              |

**Example：**

Run

```
export TORCH_HOME=$(pwd) && export PYTHONPATH=$(pwd)
```

predict.py

```python
python bin/predict.py
  --refine <True or False> \
  --model.path <path-to model> \
  --indir <path-to-target view with holes> \
  --outdir <output-path> \
  --model.checkpoin   <checkpoint name> \

```

train.py

```python
python bin/train.py
  --cn \
  --config <name of configfile, eg:lama-fourier> \
  --location <path-to-trainging dataset> \
  --data.batch_size <batch size> \
```
